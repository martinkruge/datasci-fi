---
title: "Web Scraping Tutorial // Exercise 3 // My Own Example"
author: "Martin Kruger (KRGMAR043)"
date: "`r format(Sys.Date())`"
output: 
 github_document:
 html_document:  
    keep_md: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      tidy.opts=list(width.cutoff=60),
                      tidy=TRUE)
```

**Exercise 3: Think of your own scraping example**  

A website you think contains useful or interesting information - and put together your own tutorial.  



### Netram Online Electronics Shop  
<https://www.netram.co.za/>
\ 

I will be attempting to pull a list of all of the store items available on this webpage together with the pricing and description details.


```{r, message=FALSE, warning=FALSE, include=FALSE}
rm(list=ls()) # Clean up enironment

library(rvest)
library(tidyverse)
library(stringr)

```

__Steps:__  

1.. Visit the [Netram Technologies](https://www.netram.co.za/) webpage and use the **SelectorGadget** tool to find the CSS selectors for item categories (`#categories_block_left`).   
2.. Use the **rvest** package to scrape the headings and save them as strings in R.  
3.. Read in the webpage XML using `read_html`. 

```{r, echo=TRUE}

netram_url <- "https://www.netram.co.za/"
netram_page <- read_html(netram_url)  # Grab main page XML
#netram_page

```

4.. Extract the product categories from the menu in the document with `html_nodes`.  

```{r}
   # Categories available in CSS element: '#categories_block_left a'
   netram_elements <- html_nodes(x = netram_page, css = "#categories_block_left a") 
   #netram_elements

head(netram_elements)
```


5.. To get just the text inside the element nodes we use `html_text`, with `trim = TRUE` to clean up whitespace characters.  

```{r}
# Clean up data  and save to tibble
netram_categories <- html_text(netram_elements, trim = TRUE) 
netram_categories <- as.tibble(netram_categories)

category_links <- netram_elements %>% html_attr("href")
category_links <- unique(category_links)
netram_categories$link <- category_links  # Add column to category tibble with URL link to page

head(netram_categories)
```


6.. For each of the category links, we pull the list of products (`.product-name`).  

```{r, echo=FALSE}

# Empty containers
product_list <- vector("list", 0)
product_links <- c()

# For each category grab product links
#for(i in 1:length(category_links)) {
for(i in 1:10) { # Limit to 10 categories for demonstrating purposes
  this_category_link <- category_links[i]
  this_category_name <- netram_categories$value[netram_categories$link == this_category_link]
  
  category_page <- read_html(this_category_link)
  #print(category_page)
  
  category_products <- html_nodes(x = category_page, css = ".product-name")
  product_i_links <- category_products %>% html_attr("href") 
  product_i_links <- str_subset(product_i_links,"(http).*(www.netram.co.za).*(.html)")
  
  # Save product links per category
  product_list[[this_category_name]][["links"]] <- product_i_links
  
  product_links <- c(product_links, product_i_links)

  # random wait avoids excessive requesting
  Sys.sleep(sample(seq(1, 5, by=1), 1))  # Wait a bit... not to overload the site
}

head(product_list)

```


7.. We now read each of the product pages for the detail data we want and save to a `data.frame`.  

```{r, echo=FALSE}

product_data <- data.frame()  # Empty dataframe to store product details

#i <- 4  # Debugging
for(i in 1:length(product_links)) {
#for(i in 1:min(length(product_links), 10)) { # Limit to 10 products for demonstrating purposes
  this_product_link <- product_links[i]

  this_product_page <- read_html(this_product_link)
  #write_lines(this_product_page, "output/netram_product_page.html")  # Debugging..
  
  # Grab product details
  this_product_cat <- html_nodes(x = this_product_page, css = '.title_block')
  this_product_cat <- this_product_cat %>% html_text(trim = T)
  
  this_product_reference <- html_nodes(x = this_product_page, css = "span.editable[itemprop*='sku']")
  this_product_reference <- this_product_reference %>% html_attr('content')

  this_product_name <- html_nodes(x = this_product_page, css = ".col-sm-4 h1[itemprop*='name']")
  this_product_name <- this_product_name %>% html_text(trim = T)
  
  this_product_price <- html_nodes(x = this_product_page, css = "span#our_price_display[itemprop*='price']")
  this_product_price <- this_product_price %>% html_attr('content') %>% as.numeric()
  this_product_price <- ifelse(length(this_product_price) > 0, this_product_price, NA)
 
  this_product_stock <- html_nodes(x = this_product_page, css = "span#quantityAvailable")
  this_product_stock <- this_product_stock %>% html_text(trim = T) %>% as.numeric()
  this_product_stock <- ifelse(length(this_product_stock) > 0, this_product_stock, NA)
  
  this_product_desc <- html_nodes(x = this_product_page, css = ".page-product-box .rte")
  this_product_desc <- this_product_desc %>% html_text(trim = T)
  #this_product_desc
  
  # store results
  this_product <- data.frame(sku = this_product_reference,
                             category = this_product_cat,
                             name = this_product_name, 
                             price = this_product_price, 
                             stock = this_product_stock,
                             link = this_product_link,
                             description = this_product_desc[1])

  product_data <- rbind.data.frame(product_data, this_product)

  # random wait avoids excessive requesting
  Sys.sleep(sample(seq(1, 3, by=1), 1))  # Wait a bit... not to overload the site
  
}

```

8.. Done  

```{r, echo=FALSE}
head(product_data)
```


